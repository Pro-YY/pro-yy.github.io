<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cloud | Brooke's Notes]]></title>
  <link href="https://www.yangyang.cloud/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="https://www.yangyang.cloud/"/>
  <updated>2019-12-20T17:38:59+08:00</updated>
  <id>https://www.yangyang.cloud/</id>
  <author>
    <name><![CDATA[BrookeYang(杨阳)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Distributed Load Testing by Locust]]></title>
    <link href="https://www.yangyang.cloud/blog/2018/11/13/distributed-load-testing-by-locust/"/>
    <updated>2018-11-13T10:23:38+08:00</updated>
    <id>https://www.yangyang.cloud/blog/2018/11/13/distributed-load-testing-by-locust</id>
    <content type="html"><![CDATA[<h2>Overview</h2>

<h4>What is Distributed Load Testing?</h4>

<p>In my previous post <em><a href="https://www.yangyang.cloud/blog/2018/11/05/http-load-testing-with-wrk2/">http load testing with wrk2</a></em>, we&rsquo;ve introduced some of the concepts of HTTP benchmarking. However that is not the only case, especially when the client is not as performant as the target server. More often, system developers use multiple clients (load testing clusters) to generate more loads. As shown with the picture:</p>

<p><img src="/images/distributed-load-testing-by-locust/load_arch.jpg" alt="" /></p>

<h4>Why locust?</h4>

<p>There&rsquo;s lots of open-source aimed at distributed load testing, like:</p>

<p><a href="https://github.com/locustio/locust">locust</a>
<a href="https://github.com/gatling/gatling">gatling</a>
<a href="https://github.com/shoreditch-ops/artillery">artillery</a>
<a href="https://github.com/tsenart/vegeta">vegeta</a>
<a href="https://github.com/processone/tsung">tsung</a>
<a href="https://jmeter.apache.org/">jmeter</a></p>

<p>While some of them are quite promising, in this post we choose locust, for it&rsquo;s one of the most popular in github and it&rsquo;s very easy to use and demo.</p>

<h2>Simple local test</h2>

<p>Next, let&rsquo;s start with a simple case to show how developer perform distributed load testing with locust.</p>

<h3>example workflow</h3>

<p>Install locust package
<code>
apt -y install python3-pip
pip3 install locustio
</code></p>

<p>Edit <em>locustfile.py</em>, the simplest one:
<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">locust</span> <span class="kn">import</span> <span class="n">HttpLocust</span><span class="p">,</span> <span class="n">TaskSet</span><span class="p">,</span> <span class="n">task</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">class</span> <span class="nc">UserBehavior</span><span class="p">(</span><span class="n">TaskSet</span><span class="p">):</span>
</span><span class='line'>    <span class="nd">@task</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ldquo</span><span class="p">;</span><span class="o">/&amp;</span><span class="n">rdquo</span><span class="p">;)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">class</span> <span class="nc">WebsiteUser</span><span class="p">(</span><span class="n">HttpLocust</span><span class="p">):</span>
</span><span class='line'>    <span class="n">task_set</span> <span class="o">=</span> <span class="n">UserBehavior</span>
</span><span class='line'>    <span class="n">min_wait</span> <span class="o">=</span> <span class="mi">5000</span>
</span><span class='line'>    <span class="n">max_wait</span> <span class="o">=</span> <span class="mi">9000</span>
</span></code></pre></td></tr></table></div></figure>
In fact, locust supports user scenarios by this kind of python script, which is very customizable.</p>

<p>Start master
<code>
locust --host=http://TEST_TARGET_HOST:PORT --master
</code></p>

<p>Start slave
<code>
locust --slave --master-host=MASTER_HOST
</code></p>

<p>Finally, go to master web-ui (default port on 8089), and start spawning locust!</p>

<p><img src="/images/distributed-load-testing-by-locust/1.PNG" alt="" /></p>

<p>Before launching, we should specify our expected number of users, and the hatch rate.</p>

<p><img src="/images/distributed-load-testing-by-locust/2.PNG" alt="" /></p>

<p>When testing, locust web-ui provides real-time statistics for us, including RPS, Response Time.</p>

<ul>
<li>Trouble shooting</li>
</ul>


<p>You&rsquo;ll get <code>too open files</code> issue if you forget to set it with <code>ulimit</code> command.
<img src="/images/distributed-load-testing-by-locust/4.PNG" alt="" />
<img src="/images/distributed-load-testing-by-locust/5.PNG" alt="" /></p>

<h3>problems with locust</h3>

<p>Python is not a fast language, the problem is even exacerbated when it comes to the IO-intensive application. Fortunately, locust is designed and implemented to be well scaled out, and the problem can be ameliorated a lot.</p>

<h2>AutoScaling cluster on cloud</h2>

<p>For deploying locust testing on cloud, the most suitable product is cluster management service, no matter whether it&rsquo;s the cluster for virtual machine (AutoScaling), or the cluster for container (Kubernetes Service). In this post, we conduct our load testing with AutoScaling of TencentCloud.</p>

<p>First, we build our locust image in which the locust package is installed and locust file is prepared. Second, we create our testing cluster, namely an AutoScalingGroup of our test LaunchConfiguration, which is an instance template associated with the locust image we just build. Additionally, we need to make sure that our testing cluster and target host are in the same VirtualPrivateCloud, so that they can access each other within the private network and cost little for network bandwidth. And setup the External IP as well as the Security groups for locust master node, as we&rsquo;ll access its port 8089 for the web-ui.</p>

<p>Now that we&rsquo;ve set up our load testing cluster, we could tune its Expected Instance Number on our demand.</p>

<p><img src="/images/distributed-load-testing-by-locust/6.PNG" alt="" /></p>

<ul>
<li>When to add client?</li>
</ul>


<p>Usually, as long as the final RPS increases proportionally with the number of clients, we should consider add 1 more client. In our example, 6 clients proved to be just enough.</p>

<ul>
<li>How to inspect the chart to find the best performance?</li>
</ul>


<p>When the QoS is no longer satisfied, there comes the point. As the above chart shows, the p95 is longer than 1s when the number of concurrent user reaches to 22K, and the RPS is 2830 by that time. That&rsquo;s it.</p>

<h2>Conclusions</h2>

<p>By this post, we&rsquo;ve completed an example of distributed load testing. Although there&rsquo;s a plenty of choice of testing tools, the locust is such an easy-to-use tool to help us understand the basic concepts. Thanks to the cloud-managed service like AutoScaling, we can manage our workload cluster with ease. And happy benchmarking!</p>

<h2>References</h2>

<ul>
<li><a href="https://locust.io/">locust.io official page</a></li>
<li><a href="https://cloud.tencent.com/product/as">TencentCloud AutoScaling</a></li>
<li><a href="https://cloud.google.com/solutions/distributed-load-testing-using-kubernetes">distributed-load-testing-using-kubernetes</a></li>
<li><a href="https://medium.com/@vigneshwar.ravimurugan/scriptable-and-distributed-load-testing-with-locust-in-azure-kubernetes-service-63d04c083058">Scriptable and Distributed Load Testing with Locust in Azure Kubernetes Service</a></li>
<li><a href="https://blog.realkinetic.com/load-testing-with-locust-part-1-174040afdf23">Load Testing with Locust (Part 1)</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-load-testing">an introduction to load testing</a></li>
<li><a href="https://blog.loadimpact.com/open-source-load-testing-tool-review">open source load testing tool review</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
